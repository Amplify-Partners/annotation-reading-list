# Annotation Reading List
A reading list of relevant papers and projects on foundation model annotation

## Consitutional AI and Self-Alignment
- [Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision](https://arxiv.org/abs/2305.03047) (May 2023)
- [Constitutional AI: Harmlessness from AI Feedback]([https://arxiv.org/pdf/2212.08073](https://arxiv.org/abs/2212.08073)) (Dec 2022)
